import React, { createContext, useContext, useState, ReactNode } from 'react';
import { useASRWebStreamBare } from '../hooks/useASRWebStreamBare';
import { API_ENDPOINTS } from '../config/api';
import { SUBTITLE_CONFIG } from '../config/subtitle';
import { speakerColorManager } from '../utils/speakerColors';
import { Session, WebSocketSubtitle } from '../types';

/**
 * å­—å¹•é …ç›®ä»‹é¢
 */
interface SubtitleItem {
  id: string;
  speechLogUuid?: string; // è³‡æ–™åº«ä¸­å°æ‡‰çš„ SpeechLog UUID
  content: string;
  timestamp: string;
  isNew: boolean;
  speakerName: string;
  text: string;
  previousText?: string;
  audioPath?: string; // èªè€…éŸ³æª”è·¯å¾‘
}

/**
 * éŒ„éŸ³ä¸Šä¸‹æ–‡ä»‹é¢
 */
interface RecordingContextType {
  // ç‹€æ…‹
  isRecording: boolean;
  subtitles: SubtitleItem[];
  selectedSession: Session | null;
  
  // æ–¹æ³•
  startRecording: () => void;
  stopRecording: () => void;
  setSelectedSession: (session: Session | null) => void;
  clearSubtitles: () => void;
  updateSubtitle: (id: string, newContent: string) => void;
  deleteSubtitle: (id: string) => void;
  setSubtitleIsNew: (id: string, isNew: boolean) => void;
  playSubtitleAudio: (audioPath: string) => void;  // æ’­æ”¾éŸ³æª”
}

const RecordingContext = createContext<RecordingContextType | undefined>(undefined);

/**
 * RecordingProvider çµ„ä»¶
 */
export const RecordingProvider: React.FC<{ children: ReactNode }> = ({ children }) => {
  const [selectedSession, setSelectedSession] = useState<Session | null>(null);
  const [subtitles, setSubtitles] = useState<SubtitleItem[]>([]);
  
  // ğŸš€ éŸ³æª”å¿«å–ï¼šé¿å…é‡è¤‡ä¸‹è¼‰åŒå€‹éŸ³æª”
  const audioCache = React.useRef<Map<string, HTMLAudioElement>>(new Map());
  const [isRecording, setIsRecording] = useState<boolean>(false);
  
  const mergeSameSpeaker = SUBTITLE_CONFIG.mergeSameSpeaker;

  // ä½¿ç”¨ WebSocket hook
  const { start, stop } = useASRWebStreamBare({
    wsUrl: selectedSession
      ? `${API_ENDPOINTS.stream}?session=${selectedSession.uuid}`
      : API_ENDPOINTS.stream,
    onMessage: (data: any) => {
      // è™•ç†å­—å¹•è¨Šæ¯
      if (data.type === "subtitle") {
        const subtitle = data as WebSocketSubtitle;
        const speakerName = subtitle.speakerName || 'æœªçŸ¥èªè€…';
        
        // æ ¼å¼åŒ–æ™‚é–“
        const formatTime = (dateStr: string) => {
          const date = new Date(dateStr);
          return date.toLocaleTimeString('zh-TW', { 
            hour12: true, 
            hour: 'numeric', 
            minute: '2-digit' 
          });
        };
        
        const timeInfo = subtitle.absoluteStartTime 
          ? formatTime(subtitle.absoluteStartTime)
          : formatTime(new Date().toISOString());
        
        const content = `${speakerName}ï¼š${subtitle.text || ''}`;
        
        // æ·»åŠ åˆ°å­—å¹•åˆ—è¡¨
        const newSubtitle: SubtitleItem = {
          id: `${subtitle.segmentId}-${Date.now()}`,
          speechLogUuid: subtitle.speechLogUuid, // å„²å­˜è³‡æ–™åº« UUID ä¾›ç·¨è¼¯/åˆªé™¤ä½¿ç”¨
          content: content,
          timestamp: timeInfo,
          isNew: true,
          speakerName: speakerName,
          text: subtitle.text || '',
          audioPath: subtitle.audioPath // å„²å­˜éŸ³æª”è·¯å¾‘
        };
        
        // ğŸš€ éŸ³æª”é è¼‰å„ªåŒ–ï¼šå­—å¹•ä¸€å‡ºç¾å°±é–‹å§‹é è¼‰éŸ³æª”ï¼ˆèƒŒæ™¯ä¸‹è¼‰ï¼Œä¸é˜»å¡ä»‹é¢ï¼‰
        if (subtitle.audioPath && !audioCache.current.has(subtitle.audioPath)) {
          const audioUrl = `${API_ENDPOINTS.base}/audio/${subtitle.audioPath}`;
          const audio = new Audio(audioUrl);
          audio.preload = 'auto'; // è‡ªå‹•é è¼‰å®Œæ•´éŸ³æª”
          audioCache.current.set(subtitle.audioPath, audio);
          console.log('ğŸµ èƒŒæ™¯é è¼‰éŸ³æª”:', subtitle.audioPath);
        }
        
        setSubtitles((prev) => {
          // æª¢æŸ¥æ˜¯å¦é–‹å•Ÿåˆä½µåŠŸèƒ½ä¸”èˆ‡ä¸Šä¸€å€‹å­—å¹•æ˜¯åŒä¸€èªè€…
          if (mergeSameSpeaker && prev.length > 0) {
            const lastSubtitle = prev[prev.length - 1];
            if (lastSubtitle.speakerName === speakerName) {
              // åŒä¸€èªè€…ï¼Œåˆä½µæ–‡å­—
              const updatedPrev = prev.slice(0, -1).map(item => ({ ...item, isNew: false }));
              const mergedSubtitle: SubtitleItem = {
                ...lastSubtitle,
                text: lastSubtitle.text + ' ' + newSubtitle.text,
                content: `${speakerName}ï¼š${lastSubtitle.text + ' ' + newSubtitle.text}`,
                timestamp: timeInfo,
                isNew: true,
                previousText: `${speakerName}ï¼š${lastSubtitle.text}`
              };
              return [...updatedPrev, mergedSubtitle];
            }
          }
          
          // ä¸åŒèªè€…æˆ–ç¬¬ä¸€å€‹å­—å¹•ï¼Œå‰µå»ºæ–°çš„å­—å¹•å¡ç‰‡
          const updatedPrev = prev.map(item => ({ ...item, isNew: false }));
          return [...updatedPrev, newSubtitle];
        });
      } else {
        // å…¶ä»–è¨Šæ¯
        console.log('ğŸ“© WebSocket message:', data);
      }
    },
    onError: (err) => {
      console.error('âŒ WebSocket error:', err);
    },
    onState: (s) => {
      setIsRecording(s.recording);
    },
  });

  /**
   * é–‹å§‹éŒ„éŸ³
   */
  const startRecording = () => {
    start();
  };

  /**
   * åœæ­¢éŒ„éŸ³
   */
  const stopRecording = () => {
    stop();
  };

  /**
   * æ¸…é™¤å­—å¹•
   */
  const clearSubtitles = () => {
    setSubtitles([]);
    speakerColorManager.reset();
  };

  /**
   * æ›´æ–°å­—å¹•å…§å®¹ï¼ˆåŒæ™‚æ›´æ–°å‰ç«¯å’Œè³‡æ–™åº«ï¼‰
   */
  const updateSubtitle = async (id: string, newContent: string) => {
    // å…ˆæ‰¾åˆ°å°æ‡‰çš„å­—å¹•é …ç›®
    const subtitle = subtitles.find(item => item.id === id);
    
    // æ›´æ–°å‰ç«¯ç‹€æ…‹
    setSubtitles((prev) =>
      prev.map((item) =>
        item.id === id
          ? {
              ...item,
              content: newContent,
              text: newContent.replace(/^[^ï¼š]+ï¼š/, ''),
              isNew: false
            }
          : item
      )
    );

    // å¦‚æœæœ‰ speechLogUuidï¼ŒåŒæ­¥æ›´æ–°è³‡æ–™åº«
    if (subtitle?.speechLogUuid) {
      try {
        const { apiService } = await import('../services/api');
        await apiService.updateSpeechLog(subtitle.speechLogUuid, {
          content: newContent.replace(/^[^ï¼š]+ï¼š/, ''), // ç§»é™¤èªè€…åç¨±ï¼Œåªä¿ç•™ç´”æ–‡å­—
        });
        console.log(`âœ… æˆåŠŸæ›´æ–°è³‡æ–™åº« SpeechLog: ${subtitle.speechLogUuid}`);
      } catch (error) {
        console.error('âŒ æ›´æ–°è³‡æ–™åº«å¤±æ•—:', error);
        // å¯ä»¥åœ¨é€™è£¡åŠ å…¥éŒ¯èª¤æç¤ºçµ¦ä½¿ç”¨è€…
      }
    }
  };

  /**
   * åˆªé™¤å­—å¹•ï¼ˆåŒæ™‚åˆªé™¤å‰ç«¯å’Œè³‡æ–™åº«ï¼‰
   */
  const deleteSubtitle = async (id: string) => {
    // å…ˆæ‰¾åˆ°å°æ‡‰çš„å­—å¹•é …ç›®
    const subtitle = subtitles.find(item => item.id === id);
    
    // åˆªé™¤å‰ç«¯ç‹€æ…‹
    setSubtitles((prev) => prev.filter((item) => item.id !== id));

    // å¦‚æœæœ‰ speechLogUuidï¼ŒåŒæ­¥åˆªé™¤è³‡æ–™åº«
    if (subtitle?.speechLogUuid) {
      try {
        const { apiService } = await import('../services/api');
        await apiService.deleteSpeechLog(subtitle.speechLogUuid);
        console.log(`âœ… æˆåŠŸåˆªé™¤è³‡æ–™åº« SpeechLog: ${subtitle.speechLogUuid}`);
      } catch (error) {
        console.error('âŒ åˆªé™¤è³‡æ–™åº«å¤±æ•—:', error);
        // å¯ä»¥åœ¨é€™è£¡åŠ å…¥éŒ¯èª¤æç¤ºçµ¦ä½¿ç”¨è€…
      }
    }
  };

  /**
   * è¨­ç½®å­—å¹•çš„ isNew ç‹€æ…‹
   */
  const setSubtitleIsNew = (id: string, isNew: boolean) => {
    setSubtitles((prev) =>
      prev.map((item) => (item.id === id ? { ...item, isNew } : item))
    );
  };

  /**
   * æ’­æ”¾éŸ³æª”ï¼ˆå„ªåŒ–ç‰ˆï¼šä½¿ç”¨å¿«å–é¿å…é‡è¤‡ä¸‹è¼‰ï¼‰
   */
  const playSubtitleAudio = (audioPath: string) => {
    if (!audioPath) {
      console.warn('âš ï¸ æ²’æœ‰éŸ³æª”è·¯å¾‘');
      return;
    }
    
    // ğŸš€ æª¢æŸ¥å¿«å–ï¼Œé¿å…é‡è¤‡ä¸‹è¼‰åŒå€‹éŸ³æª”
    let audio = audioCache.current.get(audioPath);
    
    if (!audio) {
      // ç¬¬ä¸€æ¬¡æ’­æ”¾ï¼šå‰µå»ºæ–°çš„ Audio ç‰©ä»¶ä¸¦å¿«å–
      const audioUrl = `${API_ENDPOINTS.base}/audio/${audioPath}`;
      audio = new Audio(audioUrl);
      
      // é è¼‰å…¥éŸ³æª”å…ƒæ•¸æ“šï¼ˆåŠ é€Ÿé¦–æ¬¡æ’­æ”¾ï¼‰
      audio.preload = 'metadata';
      
      // å¿«å–é€™å€‹ Audio ç‰©ä»¶
      audioCache.current.set(audioPath, audio);
      
      console.log('ğŸµ é¦–æ¬¡è¼‰å…¥éŸ³æª”:', audioPath);
    } else {
      // ä½¿ç”¨å¿«å–çš„ Audio ç‰©ä»¶ï¼Œç›´æ¥æ’­æ”¾
      console.log('âš¡ ä½¿ç”¨å¿«å–éŸ³æª”:', audioPath);
    }
    
    // é‡ç½®æ’­æ”¾ä½ç½®ä¸¦æ’­æ”¾
    audio.currentTime = 0;
    audio.play().catch(error => {
      console.error('âŒ æ’­æ”¾éŸ³æª”å¤±æ•—:', error);
    });
  };

  const value: RecordingContextType = {
    isRecording,
    subtitles,
    selectedSession,
    startRecording,
    stopRecording,
    setSelectedSession,
    clearSubtitles,
    updateSubtitle,
    deleteSubtitle,
    setSubtitleIsNew,
    playSubtitleAudio,
  };

  return (
    <RecordingContext.Provider value={value}>
      {children}
    </RecordingContext.Provider>
  );
};

/**
 * ä½¿ç”¨éŒ„éŸ³ä¸Šä¸‹æ–‡çš„ Hook
 */
export const useRecording = (): RecordingContextType => {
  const context = useContext(RecordingContext);
  if (!context) {
    throw new Error('useRecording must be used within a RecordingProvider');
  }
  return context;
};
